<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ù…ØªØ±Ø¬Ù… Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <h1>Ù…ØªØ±Ø¬Ù… Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</h1>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="output">
    <p id="translatedText">...</p>
    <button onclick="speakText()">ðŸ”Š Ù†Ø·Ù‚</button>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.min.js"></script>
  <script src="script.js"></script>
</body>
</html>

body {
  font-family: Arial, sans-serif;
  text-align: center;
  direction: rtl;
  background-color: #f0f0f0;
}

video, canvas {
  width: 640px;
  height: 480px;
  border: 1px solid #ccc;
  margin: 10px auto;
  display: block;
}

#output {
  margin-top: 20px;
}

button {
  padding: 10px 20px;
  font-size: 16px;
}

const videoElement = document.getElementById('video');
const canvasElement = document.getElementById('canvas');
const canvasCtx = canvasElement.getContext('2d');
const translatedTextElement = document.getElementById('translatedText');

// Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³ÙŠØ·Ø© Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ (Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ)
const gestures = {
  'Ø£': [/* Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ø­Ø±Ù Ø£ */],
  'Ø¨': [/* Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ø­Ø±Ù Ø¨ */],
  // Ø£Ø¶Ù Ø¨Ù‚ÙŠØ© Ø§Ù„Ø­Ø±ÙˆÙ Ù‡Ù†Ø§
};

// Ø¯Ø§Ù„Ø© Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
function recognizeGesture(landmarks) {
  // Ù‡Ù†Ø§ ØªØ¶Ø¹ÙŠÙ† Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† landmarks ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  // ÙˆØªØ¹ÙŠØ¯ÙŠÙ† Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚
  // Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ·ÙˆÙŠØ±
  return 'Ø£'; // Ù…Ø«Ø§Ù„: Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±Ù Ø£
}

function speakText() {
  const text = translatedTextElement.innerText;
  if (text && text !== '...') {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ar-SA';
    window.speechSynthesis.speak(utterance);
  }
}

const hands = new Hands({
  locateFile: (file) => {
    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
  }
});

hands.setOptions({
  maxNumHands: 1,
  modelComplexity: 1,
  minDetectionConfidence: 0.7,
  minTrackingConfidence: 0.7
});

hands.onResults((results) => {
  canvasCtx.save();
  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
  canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
  if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
    for (const landmarks of results.multiHandLandmarks) {
      drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 2 });
      drawLandmarks(canvasCtx, landmarks, { color: '#FF0000', lineWidth: 1 });
      const recognizedChar = recognizeGesture(landmarks);
      translatedTextElement.innerText = recognizedChar;
    }
  }
  canvasCtx.restore();
});

const camera = new Camera(videoElement, {
  onFrame: async () => {
    await hands.send({ image: videoElement });
  },
  width: 640,
  height: 480
});
camera.start();
